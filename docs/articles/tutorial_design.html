<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Designing a study • DRpower</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Designing a study">
<meta property="og:description" content="DRpower">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">DRpower</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.0.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    How it works
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/rationale1_background.html">Background</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Analysing data</li>
    <li>
      <a href="../articles/rationale2_issue.html">CIs and overdispersion</a>
    </li>
    <li>
      <a href="../articles/rationale3_design_effect.html">The design effect</a>
    </li>
    <li>
      <a href="../articles/rationale4_weaknesses.html">Weaknesses with the traditional approach</a>
    </li>
    <li>
      <a href="../articles/rationale5_bayesian.html">A Bayesian approach</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Designing a study</li>
    <li>
      <a href="../articles/rationale6_master_protocol.html">Sample size calculation in the 2020 master protocol</a>
    </li>
    <li>
      <a href="../articles/rationale7_ztest.html">The one-sample z-test</a>
    </li>
    <li>
      <a href="../articles/rationale8_power.html">Power and sample size in the DRpower model</a>
    </li>
  </ul>
</li>
<li>
  <a href="../articles/installation.html">Installation</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/tutorial_design.html">Designing a study</a>
    </li>
    <li>
      <a href="../articles/tutorial_analysis.html">Analysing data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Misc
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/mathematical_details.html">Mathematical details</a>
    </li>
    <li>
      <a href="../articles/historical_analysis.html">Historical analysis</a>
    </li>
    <li>
      <a href="../articles/summarise_prevalence.html">How to summarise the prevalence</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mrc-ide/DRpower/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Designing a study</h1>
                        <h4 data-toc-skip class="author">Bob Verity</h4>
            
            <h4 data-toc-skip class="date">Last updated: 12 Dec
2023</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/mrc-ide/DRpower/blob/HEAD/vignettes/tutorial_design.Rmd" class="external-link"><code>vignettes/tutorial_design.Rmd</code></a></small>
      <div class="hidden name"><code>tutorial_design.Rmd</code></div>

    </div>

    
    
<p>This tutorial demonstrates how you can use the <em>DRpower</em>
package in the design phase of a <em>pfhrp2/3</em> deletion study to
ensure you have adequate power. This takes a purely statistical view of
the problem; the results presented here should be taken alongside other
considerations such as logistical, financial and ethical factors.</p>
<p>This tutorial covers:</p>
<ul>
<li>Using sample size tables</li>
<li>Interpreting power curves</li>
<li>Refining sample sizes based on real-world constraints and
recalculating power</li>
<li>Accounting for dropout, and working out how many suspected cases to
enrol</li>
<li>Using the same study design for other molecular end-points,
including detecting rare variants and estimating a drug resistance
marker to within a known margin of error</li>
</ul>
<div class="section level2">
<h2 id="consult-sample-size-tables">1. Consult sample size tables<a class="anchor" aria-label="anchor" href="#consult-sample-size-tables"></a>
</h2>
<p>Our aim is to conduct a multi-site survey to test the prevalence of
<em>pfhrp2/3</em> deletions against a defined threshold. The question
is; how many sites should I use and how many samples per site?</p>
<p>The fastest way to get an idea of adequate sample size is to consult
pre-computed sample size tables. These are distributed as part of the
<em>DRpower</em> package and can be accessed through the
<code>df_ss</code> object. This data.frame contains sample sizes for a
wide range of parameter combinations, so we will start by filtering down
to the parameters we care about. In our case, we will power the study to
detect a prevalence of 10% deletions in our domain, and we will assume
an intra-cluster correlation coefficient of 0.05 based on <a href="articles/historical_analysis.html">historical data</a>:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get sample size table for parameters of interest</span></span>
<span><span class="fu"><a href="../reference/get_sample_size_table.html">get_sample_size_table</a></span><span class="op">(</span>prevalence <span class="op">=</span> <span class="fl">0.1</span>, ICC <span class="op">=</span> <span class="fl">0.05</span>, prev_thresh <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 19 × 2</span></span></span>
<span><span class="co">#&gt;    n_clust `0.1`</span></span>
<span><span class="co">#&gt;      <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span>       2    <span style="color: #BB0000;">NA</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span>       3    <span style="color: #BB0000;">NA</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span>       4    <span style="color: #BB0000;">NA</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span>       5   496</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span>       6   113</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span>       7    68</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span>       8    51</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span>       9    37</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span>      10    30</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span>      11    25</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">11</span>      12    22</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">12</span>      13    17</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">13</span>      14    15</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">14</span>      15    14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">15</span>      16    13</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">16</span>      17    11</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">17</span>      18    11</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">18</span>      19    10</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">19</span>      20     9</span></span></code></pre></div>
<p>Note that <strong>these values are only valid if you intend to
analyse your data using the DRpower model</strong>. If you plan to do a
different statistical analysis then you need a different power
analysis.</p>
<p>We can see that at least 5 sites are needed, otherwise sample sizes
are too large to be reported in this table. It’s also interesting to
note that the total sample size (<code>n_clust * N_opt</code>)
<em>decreases</em> as we recruit more sites For example, a 6-site design
would require 678 samples in total, but a 10-site design would require
only 300. This is one of <em>many</em> arguments for recruiting as many
sites as possible.</p>
<p>Let’s assume that we can only recruit 6 sites for logistical reasons,
meaning we are aiming for 113 samples per site. These sites can be
chosen through randomisation of all health facilities, or by using
predesignated sentinel surveillance sites. In the latter case, it is
important that sentinel sites are chosen to be representative of the
population in the domain as a whole (e.g. in terms of demographic and
social characteristics), otherwise we risk getting a biased view of the
prevalence of <em>pfhrp2/3</em> deletions.</p>
</div>
<div class="section level2">
<h2 id="consult-power-curves">2. Consult power curves<a class="anchor" aria-label="anchor" href="#consult-power-curves"></a>
</h2>
<p>Although sample size tables are a good starting point, they do not
tell us how power is changing with <span class="math inline">\(N\)</span>. It could be that the curve is very
steep, in which case dropping even just a few samples would really hurt
our power. On the other hand, it could be that the curve is very
shallow, in which case we have some more wiggle room.</p>
<p>All of the power curves that were used to produce the sample size
tables are distributed with the <em>DRpower</em> package and accessible
via the <code>df_sim</code> object. We can also visualise them directly
using the <code><a href="../reference/plot_power.html">plot_power()</a></code> function:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># plot power as a function of per-site sample size</span></span>
<span><span class="fu"><a href="../reference/plot_power.html">plot_power</a></span><span class="op">(</span>n_clust <span class="op">=</span> <span class="fl">6</span>, prevalence <span class="op">=</span> <span class="fl">0.1</span>, N_max <span class="op">=</span> <span class="fl">200</span><span class="op">)</span></span></code></pre></div>
<p><img src="tutorial_design_files/figure-html/unnamed-chunk-4-1.png" width="700"></p>
<p>We find that the power curve is fairly shallow around the chosen
value of N = 113. For example, the value N = 70 still achieves 75%
power. We need to be pragmatic about these numbers, and not stick
dogmatically to the target value of 80% power without thinking about
what it means. We should remember that power is defined as the
probability of finding an interesting result if it is there, so a study
with 75% power has almost as good a chance of success as a study with
80% power. It is certainly not the case that if we fail to hit 80% then
the study is completely invalid. This is important because a drop in
sample size from 113 per site to 70 per site may be the difference
between a study that is feasible to conduct and one that is not. We need
to balance these factors against each other when coming up with a study
design.</p>
<p>That being said, we should not allow power to drop too low or the
study may not be worth doing. In our case we will stick to the target
value of 113 samples per site, as we believe we can raise funds to this
level and successfully carry out the study with this sample size.</p>
</div>
<div class="section level2">
<h2 id="refine-sample-sizes">3. Refine sample sizes<a class="anchor" aria-label="anchor" href="#refine-sample-sizes"></a>
</h2>
<p>Next, we should examine our 6 sites individually to see if they are
able to recruit 113 samples. Ideally, this should be informed by
historical incidence trends at each of the sites, which can give a good
indication of how many malaria cases tend to be seen throughout the
transmission season.</p>
<p>In our case, let’s assume that two sites are in low transmission
areas, meaning they can only recruit 60 samples during the study time
frame. Another two sites are very small, and only have the capacity to
enrol 40 samples due to staffing issues.</p>
<p>The question is - how badly do these smaller sample sizes hurt our
power? We cannot work this out from sample size tables or power curves
because these assume the same sample size in each site. But we can
explore power directly using the <code><a href="../reference/get_power_threshold.html">get_power_threshold()</a></code>
function:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/get_power_threshold.html">get_power_threshold</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">113</span>, <span class="fl">113</span>, <span class="fl">60</span>, <span class="fl">60</span>, <span class="fl">40</span>, <span class="fl">40</span><span class="op">)</span>,   <span class="co"># new sample sizes per site</span></span>
<span>                    prevalence <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>                    ICC <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>                    prev_thresh <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>                    reps <span class="op">=</span> <span class="fl">1e3</span><span class="op">)</span></span>
<span><span class="co">#&gt;   prev_thresh power lower upper</span></span>
<span><span class="co">#&gt; 1        0.05  73.7 70.85 76.41</span></span></code></pre></div>
<p>We find that power is slightly lower than before, probably around
74%. We could try to balance things out by obtaining more samples from
our remaining two sites:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/get_power_threshold.html">get_power_threshold</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">250</span>, <span class="fl">250</span>, <span class="fl">60</span>, <span class="fl">60</span>, <span class="fl">40</span>, <span class="fl">40</span><span class="op">)</span>,   <span class="co"># rebalanced cluster sizes</span></span>
<span>                    prevalence <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>                    ICC <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>                    prev_thresh <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>                    reps <span class="op">=</span> <span class="fl">1e3</span><span class="op">)</span></span>
<span><span class="co">#&gt;   prev_thresh power lower upper</span></span>
<span><span class="co">#&gt; 1        0.05  77.7 74.99 80.25</span></span></code></pre></div>
<p>This rebalancing has helped, power is now back up to around 78%, but
it comes at the cost of obtaining more samples. The total sample size
has now gone up to 700 from the original 678.</p>
<p>As an aside, compare this with what happens if we were able to
recruit just one more site, rather than expanding our existing
sites:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/get_power_threshold.html">get_power_threshold</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">113</span>, <span class="fl">113</span>, <span class="fl">60</span>, <span class="fl">60</span>, <span class="fl">40</span>, <span class="fl">40</span>, <span class="fl">40</span><span class="op">)</span>,   <span class="co"># one more site of size 40</span></span>
<span>                    prevalence <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>                    ICC <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>                    prev_thresh <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>                    reps <span class="op">=</span> <span class="fl">1e3</span><span class="op">)</span></span>
<span><span class="co">#&gt;   prev_thresh power lower upper</span></span>
<span><span class="co">#&gt; 1        0.05  78.2 75.51 80.72</span></span></code></pre></div>
<p>Power is now recovered to around 78% while the total sample size is
only 466. This emphasises the point that <em>where possible</em> we
should put our efforts into recruiting more sites rather than increasing
per-site sample sizes.</p>
<p>In our case, we assume a hard limit of 6 sites, so we will stick with
the rebalanced numbers:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># final sample sizes per site</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">250</span>, <span class="fl">250</span>, <span class="fl">60</span>, <span class="fl">60</span>, <span class="fl">40</span>, <span class="fl">40</span><span class="op">)</span></span></code></pre></div>
<p>This should give us power of around 78% (somewhere in the range 75%
to 80%), which is a balance between the target power we would like and
what we can realistically achieve given real world constraints.</p>
</div>
<div class="section level2">
<h2 id="account-for-dropout">4. Account for dropout<a class="anchor" aria-label="anchor" href="#account-for-dropout"></a>
</h2>
<p>It is always sensible to account for dropout, meaning samples that,
for whatever reason, do not make it all the way to the final analysis.
Reasons can include people withdrawing consent from the study, RDTs
getting lost, samples getting contaminated or failing the molecular
laboratory methods. Although these events might be unlikely, failing to
account for potential dropout makes our study quite fragile to
unforeseen events that can hurt our power. A local technician is often
the best person to give informed advice on the expected dropout. In our
case we will assume dropout of 10%, meaning we need to divide through by
0.9:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">N_adjusted</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">ceiling</a></span><span class="op">(</span><span class="va">N</span> <span class="op">/</span> <span class="fl">0.9</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">N_adjusted</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 278 278  67  67  45  45</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/base/Round.html" class="external-link">ceiling()</a></code> function rounds values up to the nearest
whole number.</p>
<p>Note that these numbers refer to <em>confirmed malaria cases</em> (by
some gold standard that is <em>not</em> HRP2-based RDTs). When designing
a study we may need to know how many <em>suspected</em> malaria cases to
enrol, which may be much higher as suspected malaria cases often come
back negative due to the symptoms overlapping with other illnesses. To
calculate the number of suspected cases that we need to enrol we should
divide our sample sizes through by the expected positive fraction. For
example, if we expect 40% of suspected cases to come back positive then
we would do the following:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">N_suspected</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">ceiling</a></span><span class="op">(</span><span class="va">N_adjusted</span> <span class="op">/</span> <span class="fl">0.4</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">N_suspected</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 695 695 168 168 113 113</span></span></code></pre></div>
<p>Here, we have assumed the same positive fraction over all sites, but
if you have data from individual sites that can be used then that is
even better. We might also expect the positive fraction to have a
relationship with transmission intensity, in which case we can
incorporate this information.</p>
<p>To be completely clear about what each of these numbers mean:</p>
<ul>
<li>
<code>N_suspected</code> gives the number of
<strong>suspected</strong> malaria cases that we expect to enrol (1952
in total)</li>
<li>
<code>N_adjusted</code> gives the number of
<strong>confirmed</strong> malaria cases that we expect to enrol (780 in
total)</li>
<li>
<code>N</code> gives the number of <strong>confirmed</strong>
malaria cases that we expect to end up with at the end of the study
<strong>after dropout</strong> (700 in total)</li>
</ul>
<p>At this stage, it is worth doing a sanity check with the staff at the
local facilities to ensure they will be able to enrol these numbers
within the study period. This is also the point at which we can do full
budget calculations.</p>
</div>
<div class="section level2">
<h2 id="iterate-and-improve">5. Iterate and improve<a class="anchor" aria-label="anchor" href="#iterate-and-improve"></a>
</h2>
<p>Although we have completed a full statistical analysis of the number
of sites and samples, we should not think of these values as set in
stone. Rather, they give a first sketch of a study design that may be
workable, and that has good statistical properties. But if this turns
out to be impractical, either from logistical or budgetary perspectives,
then we are free to explore variations until we find something that will
work. What we should <em>not</em> do is 1) continue doggedly with a plan
that we believe will fail in practice, or 2) throw all statistical
arguments out the window and just collect whatever samples we can get
our hands on. It is usually possible to balance statistical arguments
against real world constraints to get something that satisfies both.</p>
</div>
<div class="section level2">
<h2 id="detecting-rare-variants-bonus-section">6. Detecting rare variants (bonus section)<a class="anchor" aria-label="anchor" href="#detecting-rare-variants-bonus-section"></a>
</h2>
<p>We often plan on using the same samples for multiple reasons. For
example, it is common to look for drug resistance markers at the same
time as <em>pfhrp2/3</em> deletions. In this case, we should perform a
separate power analysis and sample size calculation for these other
end-points and always <em>take the largest sample size</em> between the
two analyses, as this is the one that will give sufficient power over
all end-points.</p>
<p>The <em>DRpower</em> package contains simple functions for exploring
other questions. For example, imagine we are looking to detect the
presence of rare variants, such as <em>pfk13</em> mutations conferring
partial resistance to artemisinin. Here, we are asking whether the
prevalence is greater than zero in the domain, and a single positive
result confirms that there are. The function
<code><a href="../reference/get_power_presence.html">get_power_presence()</a></code> tells us our power to detect
<em>any</em> mutants. Similar to the <em>pfhrp2/3</em> deletion
analysis, this assumes we will run a multi-site study and summarise
results over all sites, meaning we need to account for intra-cluster
correlation:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get power to detect a 1% variant at the domain level</span></span>
<span><span class="fu"><a href="../reference/get_power_presence.html">get_power_presence</a></span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, prevalence <span class="op">=</span> <span class="fl">0.01</span>, ICC <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 86.5711</span></span></code></pre></div>
<p>We can see that the same sample sizes from the <em>pfhrp2/3</em>
deletion study design also give us more than 80% power to detect rare
variants at the domain level. Another way to approach this problem is to
use the function <code><a href="../reference/get_sample_size_presence.html">get_sample_size_presence()</a></code>, which tells us
how many samples we need in each site to achieve 80% power:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># how many samples would we need to achieve 80% power in the presence analysis</span></span>
<span><span class="fu"><a href="../reference/get_sample_size_presence.html">get_sample_size_presence</a></span><span class="op">(</span>n_clust <span class="op">=</span> <span class="fl">6</span>, prevalence <span class="op">=</span> <span class="fl">0.01</span>, ICC <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 58</span></span></code></pre></div>
<p>So six sites with 58 samples each would do it. From our
<em>pfhrp2/3</em> analysis we have variable sample sizes, some above
this level and some below, which is why the
<code><a href="../reference/get_power_presence.html">get_power_presence()</a></code> method was useful.</p>
<p>What if we are not interested in summarising at the domain level, and
instead we want to know our power in each of the individual sites? We
can use the same functions as before, now run independently over each of
the sites. We should fix the ICC at zero because this is no longer a
multi-site study:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># how many samples are needed in an independent analysis</span></span>
<span><span class="fu"><a href="../reference/get_sample_size_presence.html">get_sample_size_presence</a></span><span class="op">(</span>n_clust <span class="op">=</span> <span class="fl">1</span>, prevalence <span class="op">=</span> <span class="fl">0.01</span>, ICC <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 161</span></span>
<span></span>
<span><span class="co"># get power to detect a 1% variant in each of the individual sites</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mapply.html" class="external-link">mapply</a></span><span class="op">(</span><span class="va">get_power_presence</span>, <span class="va">N</span>, MoreArgs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>ICC <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 91.89415 91.89415 45.28434 45.28434 33.10282 33.10282</span></span></code></pre></div>
<p>We find that 161 samples are needed for a single site to be powered
to detect a rare variant at 1% prevalence. Accordingly, only our large
sites (250 samples) achieve power over 80%, and the smaller sites with
60 and 40 samples have power below 50%. Therefore we would conclude that
4 out of our 6 sites are underpowered at the individual level, and so we
may be better off pooling results to the domain level.</p>
</div>
<div class="section level2">
<h2 id="controling-the-margin-of-error-bonus-section">7. Controling the margin of error (bonus section)<a class="anchor" aria-label="anchor" href="#controling-the-margin-of-error-bonus-section"></a>
</h2>
<p>What if we also plan on using the same samples to look for a drug
resistance marker that we already believe to be at high prevalence? In
this case, it can be useful to consider what will be the expected margin
of error in our analysis. This is not the same as a power analysis, as
we are not conducting a hypothesis test. Rather, we are trying to choose
a sample size that gives us a certain level of precision.</p>
<p>The <code><a href="../reference/get_margins.html">get_sample_size_margin()</a></code> function tells us the
per-site sample size needed to achieve a given margin of error (MOE) if
we plan on pooling results over multiple sites. Here, we assume that the
prevalence of the marker is 20% in the population, and we aim to
estimate this to within plus or minus 10%:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get sample size needed to achieve 10% MOE if prevalence is 20% and we have 6 sites</span></span>
<span><span class="fu"><a href="../reference/get_margins.html">get_sample_size_margin</a></span><span class="op">(</span>MOE <span class="op">=</span> <span class="fl">0.1</span>, n_clust <span class="op">=</span> <span class="fl">6</span>, prevalence <span class="op">=</span> <span class="fl">0.2</span>, ICC <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 20</span></span></code></pre></div>
<p>We only need 20 samples to achieve this level of precision, which we
are well above. We can also use the <code><a href="../reference/get_margins.html">get_margin()</a></code> function
to tell us what our MOE would be given a known sample size:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get MOE assuming 40 samples in each of 6 sites</span></span>
<span><span class="fu"><a href="../reference/get_margins.html">get_margin</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fl">40</span>, n_clust <span class="op">=</span> <span class="fl">6</span>, prevalence <span class="op">=</span> <span class="fl">0.2</span>, ICC <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt;    lower    upper </span></span>
<span><span class="co">#&gt; 11.30813 28.69187</span></span></code></pre></div>
<p>With 40 samples we would expect our 95% CI to range from around 11.3%
to 28.7%, in other words a MOE of around 8.7%.</p>
<p>The formula used above is extremely simple. It does not allow for
different sample sizes per site, and it also assumes that we know the
ICC exactly rather than estimating it from data. An alternative approach
is to use the <em>DRpower</em> Bayesian model to estimate the
prevalence. In other words, we plan on using the
<code><a href="../reference/get_posterior.html">get_prevalence()</a></code> function to obtain a 95% Bayesian credible
interval (CrI). If we plan to estimate prevalence this way, then we
should use the function <code><a href="../reference/get_margin_Bayesian.html">get_margin_Bayesian()</a></code> to estimate
our MOE. This function works by simulation, and allows for different
sample sizes in each site:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get MOE when using DRpower Bayesian model</span></span>
<span><span class="fu"><a href="../reference/get_margin_Bayesian.html">get_margin_Bayesian</a></span><span class="op">(</span><span class="va">N</span>, prevalence <span class="op">=</span> <span class="fl">0.2</span>, ICC <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt;       estimate   CI_2.5  CI_97.5</span></span>
<span><span class="co">#&gt; lower  12.6323 12.03405 13.23055</span></span>
<span><span class="co">#&gt; upper  31.0595 30.12544 31.99356</span></span></code></pre></div>
<p>Using this method, we expect our 95% CrI to range from around 12.6%
to 31%. Note that this MOE is different in the lower and upper
directions meaning the CrI is not symmetric. It is also narrower at the
lower end than our previous <code><a href="../reference/get_margins.html">get_margin()</a></code> estimate, but
wider at the upper end. The Bayesian model makes different assumptions,
and so in general we shouldn’t expect the CrI to be the same as the
CI.</p>
<p>In summary…</p>
<ul>
<li>We have sample sizes (<code>N</code>) that we are happy with for our
<em>pfhrp2/3</em> analysis. These don’t quite achieve 80% power, but
they are not far off. They have been chosen taking into account
logistical and feasibility constraints as well as statistical
considerations. We also know the number of suspected malaria cases that
we need to enrol (<code>N_suspected</code>).</li>
<li>The same sample sizes give us 86% power to detect rare
<em>pfk13</em> variants at 1% in the population when summarised at the
domain level. We do not have power to detect rare variants at the
individual site level in most sites.</li>
<li>The same sample sizes give us a margin of error of around 10% when
estimating the prevalence of a variant at 20% in the population.</li>
</ul>
<p>Notice that this summary considers all end-points for the same sample
sizes. We have now arrived at a detailed plan and have a good idea of
what we can expect from our results. It is up to us to decide if we want
to go ahead with this plan, or if we want to revisit assumptions and
modify the plan accordingly.</p>
<p align="center">
<button class="btn btn-primary" onclick="window.location.href='https://mrc-ide.github.io/DRpower/articles/tutorial_analysis.html';">
Next topic
</button>
</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Bob Verity, Shazia Ruybal.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
